from pathlib import Path
import os
import torch
import pandas as pd
import numpy as np
from PIL import Image
from tqdm import tqdm
from transformers import AutoImageProcessor, AutoModel

class DINOScorer:
    def __init__(self, model_name: str = "facebook/dinov2-base", device: str = "cuda"):
        self.device = torch.device("cuda" if (device == "cuda" and torch.cuda.is_available()) else "cpu")
        print(f"ğŸ¤– Device: {self.device}")
        self.processor = AutoImageProcessor.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name).to(self.device)
        self.model.eval()

    @torch.inference_mode()
    def get_features(self, img_path: str) -> torch.Tensor:
        img = Image.open(img_path).convert('RGB')
        inputs = self.processor(images=img, return_tensors="pt").to(self.device)
        outputs = self.model(**inputs)
        # Global average pooling (CLS í† í° ëŒ€ì‹  patchë“¤ì˜ í‰ê·  ì‚¬ìš© ê°€ëŠ¥, ì—¬ê¸°ì„  CLS í† í° ì‚¬ìš©)
        f = outputs.last_hidden_state[:, 0, :] 
        f = f / f.norm(dim=-1, keepdim=True)
        return f

def main():
    # 1. ê²½ë¡œ ì„¤ì •
    base_path = Path("/data1/joo/pai_bench/data/prelim_01")
    output_csv = "/data1/joo/pai_bench/results/prelim_01/metric/format/brightness/dino.csv"
    
    # ì¶œë ¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(os.path.dirname(output_csv), exist_ok=True)
    
    folders = {
        "lighten": base_path / "cropped_ligthen",
        "orig": base_path / "cropped",
        "darken": base_path / "cropped_darken"
    }
    
    # ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
    scorer = DINOScorer(device="cuda")
    
    # ê¸°ì¤€ í´ë”(regular)ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
    image_names = [f.name for f in folders["orig"].iterdir() 
                   if f.is_file() and f.suffix.lower() in image_extensions]
    
    all_results = []

    # 2. ë£¨í”„ ë° ê³„ì‚°
    for name in tqdm(image_names, desc="Calculating DINO scores"):
        paths = {k: v / name for k, v in folders.items()}
        
        # ì„¸ í´ë” ëª¨ë‘ì— íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not all(p.exists() for p in paths.values()):
            continue
            
        try:
            # íŠ¹ì„± ì¶”ì¶œ (Features)
            feat_s = scorer.get_features(str(paths["lighten"]))
            feat_r = scorer.get_features(str(paths["orig"]))
            feat_b = scorer.get_features(str(paths["darken"]))
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            score_sr = torch.cosine_similarity(feat_s, feat_r).item()
            score_rr = torch.cosine_similarity(feat_r, feat_r).item()
            score_rb = torch.cosine_similarity(feat_r, feat_b).item()
            
            all_results.append({
                "filename": name,
                "dino_lighten_orig": score_sr,
                "dino_orig_orig": score_rr,
                "dino_orig_darken": score_rb
            })
            
        except Exception as e:
            print(f"Error processing {name}: {e}")

    # 3. ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° í‰ê·  ê³„ì‚°
    if not all_results:
        print("No results were calculated. Check your file paths.")
        return

    df = pd.DataFrame(all_results)
    
    # ìµœì¢… í‰ê·  ìŠ¤ì½”ì–´ ê³„ì‚°
    avg_sr = df["dino_lighten_orig"].mean()
    avg_rr = df["dino_orig_orig"].mean()
    avg_rb = df["dino_orig_darken"].mean()
    
    print("\n" + "="*40)
    print(f"ğŸ“Š Final Average DINO Scores ({len(df)} images)")
    print("-" * 40)
    print(f"Small  â†” Regular: {avg_sr:.4f}")
    print(f"Regular â†” Regular: {avg_rr:.4f}")
    print(f"Regular â†” Big    : {avg_rb:.4f}")
    print("="*40)

    # ì „ì²´ ê²°ê³¼ ì €ì¥
    df.to_csv(output_csv, index=False)
    print(f"âœ… Results saved to {output_csv}")

if __name__ == "__main__":
    main()