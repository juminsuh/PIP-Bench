# import os
# import base64
# import json
# import csv
# from openai import OpenAI
# from dotenv import load_dotenv
# from pathlib import Path

# # --- API ì„¤ì • (ê¸°ì¡´ ìœ ì§€) ---
# env_path = Path(__file__).resolve().parent.parent.parent / '.env'
# load_dotenv(dotenv_path=env_path)
# API_KEY = os.getenv("OPENAI_API_KEY")
# client = OpenAI(api_key=API_KEY)

# # --- PROMPT (ê¸°ì¡´ Continuous Score ë²„ì „ ìœ ì§€) ---
# SYSTEM_PROMPT = """
# You are a powerful visual expert capable of accurately analyzing faces in images and determining whether two people are the same person, based on both coarse and fine-grained facial features.
# """

# USER_PROMPT = """
# [Instruction]
# You are given two images: a reference image and a generated image.
# Your task is to evaluate whether the two images show the same person based ONLY
# on identity-related facial features. Evaluate the Rubrics carefully and follow
# the Actions exactly. Do not output anything other than the rated score.

# [Rubrics]
# 1. Determine whether the two images depict the same person based on:
#    â€¢ eyes, nose, lips, face shape, skin tone
# 2. Ignore differences from:
#    lighting, color, posture, angle, expression, hairstyle, makeup,
#    accessories, image quality.
# 3. Do not overestimate or underestimate the score. Assign the score objectively. 

# [Actions]
# 1. Compare identity-related features.
# 2. Rate how similar the identities in the two images are, from 0 (different identities) to 1 (same identities).
# """

# # --- Utils ---
# MAX_RETRIES = 3
# VALID_EXT = [".jpg", ".jpeg", ".png"]

# def encode_image(path):
#     with open(path, "rb") as f:
#         return base64.b64encode(f.read()).decode("utf-8")

# def is_valid_score(text):
#     """ì‘ë‹µì´ 0~1 ì‚¬ì´ì˜ ìœ íš¨í•œ ìˆ«ìì¸ì§€ ì²´í¬"""
#     try:
#         score = float(text.strip())
#         return 0 <= score <= 1
#     except ValueError:
#         return False
    
# def get_mime(path):
#     ext = os.path.splitext(path)[1].lower()
#     return "image/png" if ext == ".png" else "image/jpeg"

# # --- í•µì‹¬ ì‹¤í–‰ í•¨ìˆ˜ (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€) ---
# def run_similarity_score(img1_path, img2_path):
#     for attempt in range(1, MAX_RETRIES + 1):
#         try:
#             img1_b64 = encode_image(img1_path)
#             img2_b64 = encode_image(img2_path)
#             img1_mime = get_mime(img1_path)
#             img2_mime = get_mime(img2_path)

#             response = client.responses.create(
#                 model="gpt-5", # ê¸°ì¡´ ëª¨ë¸ëª… ìœ ì§€
#                 input=[
#                     {"role": "system", "content": SYSTEM_PROMPT},
#                     {
#                         "role": "user",
#                         "content": [
#                             {"type": "input_text", "text": USER_PROMPT},
#                             {"type": "input_image", "image_url": f"data:{img1_mime};base64,{img1_b64}"},
#                             {"type": "input_image", "image_url": f"data:{img2_mime};base64,{img2_b64}"},
#                         ]
#                     },
#                 ],
#             )
            
#             result = response.output_text.strip()
#             if is_valid_score(result):
#                 return result
#             else:
#                 print(f"      [RETRY {attempt}] Invalid score format: {result}")
#         except Exception as e:
#             print(f"      [RETRY {attempt}] Error: {e}")
            
#     return "ERROR"

# # --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ (Size ë¹„êµ ë° CSV ì €ì¥) ---
# def main():
#     # ê²½ë¡œ ì„¤ì •
#     base_data_path = "/data1/joo/pai_bench/data/prelim_01"
#     dir_small = os.path.join(base_data_path, "cropped_small")
#     dir_regular = os.path.join(base_data_path, "cropped_regular")
#     dir_big = os.path.join(base_data_path, "cropped_big")
    
#     output_dir = "/data1/joo/pai_bench/result/prelim_01/metric/format/size"
#     os.makedirs(output_dir, exist_ok=True)
#     output_file = os.path.join(output_dir, "mcq_type1.csv")

#     # Regular í´ë” ê¸°ì¤€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ì—…
#     files = sorted([f for f in os.listdir(dir_regular) if os.path.splitext(f)[1].lower() in VALID_EXT])
    
#     results = []

#     for fname in files:
#         print(f"ğŸš€ Processing Similarity Size Test: {fname}")
        
#         path_small = os.path.join(dir_small, fname)
#         path_regular = os.path.join(dir_regular, fname)
#         path_big = os.path.join(dir_big, fname)

#         # 1. small_regular (Small vs Regular)
#         print(f"   [1/3] Small vs Regular...")
#         score_small_reg = run_similarity_score(path_small, path_regular)

#         # 2. regular_regular (Regular vs Regular)
#         print(f"   [2/3] Regular vs Regular...")
#         score_reg_reg = run_similarity_score(path_regular, path_regular)

#         # 3. regular_big (Regular vs Big)
#         print(f"   [3/3] Regular vs Big...")
#         score_reg_big = run_similarity_score(path_regular, path_big)

#         results.append({
#             "filename": fname,
#             "small_regular": score_small_reg,
#             "regular_regular": score_reg_reg,
#             "regular_big": score_reg_big
#         })

#     # CSV ì €ì¥ (ìš”ì²­í•˜ì‹  ì»¬ëŸ¼ í˜•ì‹)
#     fieldnames = ["filename", "small_regular", "regular_regular", "regular_big"]
#     with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
#         writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
#         writer.writeheader()
#         for row in results:
#             writer.writerow(row)

#     print(f"âœ… Similarity Size ë¶„ì„ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {output_file}")

# if __name__ == "__main__":
#     main()

import os
import base64
import json
import csv
import random
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path

# --- API ì„¤ì • ---
env_path = Path(__file__).resolve().parent.parent.parent.parent / '.env'
load_dotenv(dotenv_path=env_path)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- ì„¤ì • ë° ìƒìˆ˜ ---
MAX_WORKERS = 15  # ê³„ì •ì˜ RPM(ë¶„ë‹¹ ìš”ì²­ìˆ˜) ì œí•œì— ë”°ë¼ 10~20 ì‚¬ì´ ê¶Œì¥
MAX_RETRIES = 3
VALID_EXT = [".jpg", ".jpeg", ".png"]

SYSTEM_PROMPT = """
You are a powerful visual expert capable of accurately analyzing faces in images and determining whether two people are the same person, based on both coarse and fine-grained facial features.
"""

USER_PROMPT = """
[Instruction]
You are given two images: a reference image and a generated image.
Your task is to evaluate whether the two images show the same person based ONLY
on identity-related facial features. Evaluate the Rubrics carefully and follow
the Actions exactly. Do not output anything other than the rated score.

[Rubrics]
1. Determine whether the two images depict the same person based on:
   â€¢ eyes, nose, lips, face shape, skin tone
2. Ignore differences from:
   lighting, color, posture, angle, expression, hairstyle, makeup,
   accessories, image quality.
3. Do not overestimate or underestimate the score. Assign the score objectively. 

[Actions]
1. Compare identity-related features.
2. Rate how similar the identities in the two images are, from 0 (different identities) to 1 (same identities).
"""

# --- Utils ---
def encode_image(path):
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def get_mime(path):
    ext = os.path.splitext(path)[1].lower()
    return "image/png" if ext == ".png" else "image/jpeg"

def is_valid_score(text):
    try:
        score = float(text.strip())
        return 0 <= score <= 1
    except ValueError:
        return False

# --- í•µì‹¬ ì‹¤í–‰ í•¨ìˆ˜ ---
def run_similarity_score(img1_path, img2_path):
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            response = client.responses.create(
                model="gpt-5",
                input=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": [
                            {"type": "input_text", "text": USER_PROMPT},
                            {"type": "input_image", "image_url": f"data:{get_mime(img1_path)};base64,{encode_image(img1_path)}"},
                            {"type": "input_image", "image_url": f"data:{get_mime(img2_path)};base64,{encode_image(img2_path)}"},
                        ]
                    },
                ],
            )
            result = response.output_text.strip()
            if is_valid_score(result):
                return result
            time.sleep(0.5 * attempt)
        except Exception:
            time.sleep(1 * attempt)
    return "ERROR"

# --- Worker Function (Thread ë‹¨ìœ„) ---
def process_similarity_task(fname, dir_small, dir_regular, dir_big):
    p_small = os.path.join(dir_small, fname)
    p_reg = os.path.join(dir_regular, fname)
    p_big = os.path.join(dir_big, fname)

    # 3ê°€ì§€ ì¼€ì´ìŠ¤ ì‹¤í–‰
    return {
        "filename": fname,
        "small_regular": run_similarity_score(p_small, p_reg),
        "regular_regular": run_similarity_score(p_reg, p_reg),
        "regular_big": run_similarity_score(p_reg, p_big)
    }

# --- Main ---
def main():
    base_data_path = "/data1/joo/pai_bench/data/prelim_01"
    dir_small = os.path.join(base_data_path, "cropped_small")
    dir_regular = os.path.join(base_data_path, "cropped_regular")
    dir_big = os.path.join(base_data_path, "cropped_big")
    
    output_dir = "/data1/joo/pai_bench/result/prelim_01/metric/format/size"
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, "mcq_type1.csv")

    files = sorted([f for f in os.listdir(dir_regular) if os.path.splitext(f)[1].lower() in VALID_EXT])
    fieldnames = ["filename", "small_regular", "regular_regular", "regular_big"]

    print(f"ğŸš€ Similarity Size ë¶„ì„ ì‹œì‘: ì´ {len(files)}ê°œ íŒŒì¼ (Thread: {MAX_WORKERS})")

    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # ì‘ì—… ë“±ë¡
            futures = {
                executor.submit(process_similarity_task, f, dir_small, dir_regular, dir_big): f 
                for f in files
            }

            count = 0
            for future in as_completed(futures):
                fname = futures[future]
                try:
                    result = future.result()
                    writer.writerow(result)
                    csvfile.flush() # ì‹¤ì‹œê°„ ë°ì´í„° íŒŒì¼ ê¸°ë¡
                    
                    count += 1
                    if count % 10 == 0:
                        print(f"âœ… ì§„í–‰: {count}/{len(files)} ({(count/len(files))*100:.1f}%)")
                except Exception as e:
                    print(f"âŒ {fname} ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}")

    print(f"âœ¨ ë¶„ì„ì´ ëª¨ë‘ ëë‚¬ìŠµë‹ˆë‹¤! ì €ì¥ ìœ„ì¹˜: {output_file}")

if __name__ == "__main__":
    main()