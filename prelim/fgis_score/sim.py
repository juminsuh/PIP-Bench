import pandas as pd
import numpy as np
import pickle
import os
from itertools import combinations
from sklearn.metrics.pairwise import cosine_similarity

def load_all_embeddings(input_dir):
    """ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  .pkl íŒŒì¼ì„ ì½ì–´ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    all_dfs = []
    print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘: {input_dir}")
    
    files = [f for f in os.listdir(input_dir) if f.endswith('.pkl')]
    for file in files:
        with open(os.path.join(input_dir, file), 'rb') as f:
            data = pickle.load(f)
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë©´ DFë¡œ ë³€í™˜, ì´ë¯¸ DFë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            df_temp = pd.DataFrame(data)
            all_dfs.append(df_temp)
    
    if not all_dfs:
        return None
        
    combined_df = pd.concat(all_dfs, ignore_index=True)
    # ì´ë¯¸ì§€ ID í¬ë§· í†µì¼ (0001, 0002...)
    combined_df['image_id'] = combined_df['image_id'].apply(lambda x: str(int(x)).zfill(4))
    return combined_df

def compute_all_pairs_similarity(df, output_path):
    """ëª¨ë“  ì´ë¯¸ì§€ ì¡°í•©ì— ëŒ€í•´ 11ê°œ ë¶€ìœ„ë³„ ìœ ì‚¬ë„ í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    # ìš”ì²­í•˜ì‹  11ê°œ ì–¼êµ´ ë¶€ìœ„ ì»¬ëŸ¼
    feature_cols = [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13]
    image_ids = df['image_id'].tolist()
    
    # ì¡°íšŒë¥¼ ë¹ ë¥´ê²Œ í•˜ê¸° ìœ„í•´ IDë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
    df_indexed = df.set_index('image_id')
    
    results = []
    # ê³ ìœ í•œ ìŒ(Pair) ìƒì„± (N * (N-1) / 2)
    pairs = list(combinations(image_ids, 2))
    total_pairs = len(pairs)
    
    print(f"ğŸš€ ì´ {len(image_ids)}ê°œì˜ ì´ë¯¸ì§€ì—ì„œ {total_pairs}ê°œì˜ ìŒì„ ê³„ì‚°í•©ë‹ˆë‹¤.")

    for i, (id1, id2) in enumerate(pairs):
        row1 = df_indexed.loc[id1]
        row2 = df_indexed.loc[id2]
        
        feature_similarities = []
        
        for col in feature_cols:
            emb1 = row1.get(col)
            emb2 = row2.get(col)
            
            # ë‘ ì´ë¯¸ì§€ ëª¨ë‘ í•´ë‹¹ ë¶€ìœ„ ì„ë² ë”©ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ
            if emb1 is not None and emb2 is not None:
                # ë°ì´í„°ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
                if isinstance(emb1, (list, np.ndarray)) and len(emb1) > 0:
                    vec1 = np.array(emb1).reshape(1, -1)
                    vec2 = np.array(emb2).reshape(1, -1)
                    
                    sim = cosine_similarity(vec1, vec2)[0][0]
                    feature_similarities.append(sim)
        
        # 11ê°œ ë¶€ìœ„ì˜ í‰ê·  ìœ ì‚¬ë„ ì‚°ì¶œ
        if len(feature_similarities) > 0:
            avg_sim = np.mean(feature_similarities)
            results.append({
                'img0': id1,
                'img1': id2,
                'fgis_sim': avg_sim,
                'features_cnt': len(feature_similarities)
            })
            
        # ì§„í–‰ ìƒí™© ì¶œë ¥ (1000ë‹¨ìœ„)
        if (i + 1) % 1000 == 0:
            print(f"â³ ì§„í–‰ ì¤‘... ({i + 1}/{total_pairs})")

    # ê²°ê³¼ ì €ì¥
    result_df = pd.DataFrame(results)
    result_df.to_csv(output_path, index=False)
    return result_df

def main():
    input_dir = "/data1/joo/pai_bench/data/prelim_01/fgis/content/emb"
    output_dir = "/data1/joo/pai_bench/results/prelim_01/metric"
    output_file = os.path.join(output_dir, "fgis.csv")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ëª¨ë“  ë°ì´í„° ë¡œë“œ
    full_df = load_all_embeddings(input_dir)
    
    if full_df is not None:
        # 2. ëª¨ë“  ì¡°í•© ìœ ì‚¬ë„ ê³„ì‚°
        final_results = compute_all_pairs_similarity(full_df, output_file)
        
        print(f"âœ… ëª¨ë“  ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()